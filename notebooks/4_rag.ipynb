{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a_rag_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text file and the persistent directory\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "file_path = os.path.join(current_dir, \"notebooks\", \"documents\", \"langchain_demo.txt\")\n",
    "persistent_directory = os.path.join(current_dir, \"notebooks\", \"db\", \"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text content from the file\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 451, which is longer than the specified 200\n",
      "Created a chunk of size 1203, which is longer than the specified 200\n",
      "Created a chunk of size 916, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "# Split the document into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document Chunks Information ---\n",
      "Number of document chunks: 5\n",
      "Sample chunk:\n",
      "LangChain: A Framework for LLM-Powered Applications\n",
      "LangChain is a powerful and flexible framework designed to simplify the development of applications that harness the capabilities of large language models (LLMs). It provides a wide range of tools, abstractions, and integrations that help developers build, customize, and optimize applications that leverage LLMs for tasks like text generation, question answering, summarization, chatbots, and more.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display information about the split documents\n",
    "print(\"\\n--- Document Chunks Information ---\")\n",
    "print(f\"Number of document chunks: {len(docs)}\")\n",
    "print(f\"Sample chunk:\\n{docs[0].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating embeddings ---\n",
      "\n",
      "--- Finished creating embeddings ---\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "print(\"\\n--- Creating embeddings ---\")\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "print(\"\\n--- Finished creating embeddings ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store ---\n",
      "\n",
      "--- Finished creating vector store ---\n"
     ]
    }
   ],
   "source": [
    "# Create the vector store and persist it automatically\n",
    "print(\"\\n--- Creating vector store ---\")\n",
    "db = Chroma.from_documents(docs, embeddings, persist_directory=persistent_directory)\n",
    "print(\"\\n--- Finished creating vector store ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"What is LangChain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant documents based on the query\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 2, \"score_threshold\": 0.7},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "LangChain: A Framework for LLM-Powered Applications\n",
      "LangChain is a powerful and flexible framework designed to simplify the development of applications that harness the capabilities of large language models (LLMs). It provides a wide range of tools, abstractions, and integrations that help developers build, customize, and optimize applications that leverage LLMs for tasks like text generation, question answering, summarization, chatbots, and more.\n",
      "\n",
      "Source: /home/mrego/Projects/workspace/langchain-notebook/notebooks/documents/langchain_demo.txt\n",
      "\n",
      "Document 2:\n",
      "LangChain: A Framework for LLM-Powered Applications\n",
      "LangChain is a powerful and flexible framework designed to simplify the development of applications that harness the capabilities of large language models (LLMs). It provides a wide range of tools, abstractions, and integrations that help developers build, customize, and optimize applications that leverage LLMs for tasks like text generation, question answering, summarization, chatbots, and more.\n",
      "\n",
      "Source: /home/mrego/Projects/workspace/langchain-notebook/notebooks/documents/langchain_demo.txt\n",
      "\n",
      "Document 3:\n",
      "LangChain Documentation: https://python.langchain.com/\n",
      "\n",
      "Source: /home/mrego/Projects/workspace/langchain-notebook/notebooks/documents/langchain_demo.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
